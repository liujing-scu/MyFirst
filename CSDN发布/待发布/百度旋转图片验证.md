# 1抓取图片

找一个安全验证的页面，用selenium截取页面快照，然后裁剪出下面的图片。

注意：图片保存的路径要用英文，不要包含中文，后面有些函数不支持路径含有中文的（比如相似度计算的那个函数）。

![image-20210918155726514](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210918155726514.png)

```
import selenium
import time
from selenium import webdriver
from PIL import Image
from selenium.webdriver.common.keys import Keys
path =r"C:\Users\Administrator\AppData\Local\Google\Chrome\Application\chromedriver.exe"
browser = webdriver.Chrome(executable_path=path)
#抓取500张图片，这些图片有很多是重复的
for i in range(0,500,1):
    browser.get("https://wappass.baidu.com/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Fp%2F3982352452&timestamp=1630048735&signature=72a227fed2dc24a90bcf68b45837af6c")
    time.sleep(10)#这里需要等一会儿，页面加载好，不然读取不到xpath定位的元素
    print(browser.page_source)
    input = browser.find_element_by_xpath('//div[@class="vcode-spin-faceboder"]')
    time.sleep(5)
    browser.save_screenshot(r'E:\login.png')
    left=input.location['x']
    top=input.location['y']
    right=left+input.size['width']
    bottom=top+input.size['height']

    im=Image.open(r'E:\login.png')
    mg=im.crop((left,top,right,bottom))
    #保存截图，命名为0.png，1.png……
    mg.save(r'E:\baidu_safe\{}.png'.format(i))
```

# 2.筛选图片

我截取并保存了500张图片，基本上是涵盖了现在的所有验证图片。这500张图片中有很多图片是一样的，只是角度不同，我们如果用人眼筛选和删除重复的图片，工作量太大了，眼睛也受不了。所以，这里还是采用脚本进行筛选。每两张图片进行比较，如果相似度大于一个阈值，就删除其中一张，保留另一张。

下面要引入相似度计算的函数，这是我直接用别人提供好的，这个算法不是我写的。https://blog.csdn.net/liu506039293/article/details/102696486这是原文的链接，如果有冒犯，请联系我进行删除，谢谢了！

```
def img_similarity(img1_path,img2_path):
    """
    :param img1_path: 图片1路径
    :param img2_path: 图片2路径
    :return: 图片相似度
    """
    try:
        # 读取图片
        img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)
        img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)

        # 初始化ORB检测器
        orb = cv2.ORB_create()
        kp1, des1 = orb.detectAndCompute(img1, None)
        kp2, des2 = orb.detectAndCompute(img2, None)

        # 提取并计算特征点
        bf = cv2.BFMatcher(cv2.NORM_HAMMING)

        # knn筛选结果
        matches = bf.knnMatch(des1, trainDescriptors=des2, k=2)

        # 查看最大匹配点数目
        good = [m for (m, n) in matches if m.distance < 0.75 * n.distance]
        # print(len(good))
        # print(len(matches))
        similary = len(good) / len(matches)
        # print("两张图片相似度为:%s" % similary)
        return similary

    except:
        print('无法计算两张图片相似度')
        return '0'
```



# 3.旋转图片得到所有角度的图片

```
img = Image.open(r"E:\0.png")
rotated_small = img.rotate(110, resample=Image.BICUBIC, expand=True)
rotated_small.save(r"E:\0-110.png")
```

# 4.标记出角度正确的图片

# 5.计算出每张图片和正确图片的角度差

# 6.计算出每张图片需要拖动的距离

# 7.实际测试

代码

```
import selenium
import time
from selenium import webdriver
from selenium.webdriver import ActionChains
from PIL import Image
from PIL import ImageChops
from selenium.webdriver.common.keys import Keys
from skimage.measure import compare_ssim
from skimage.metrics import structural_similarity
import argparse
import imutils
import cv2
import os
img_path = r'E:\qqq'
#按钮移动
def move_button():
    path = r"C:\Users\Administrator\AppData\Local\Google\Chrome\Application\chromedriver.exe"
    browser = webdriver.Chrome(executable_path=path)
    browser.get(
        "https://wappass.baidu.com/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Fp%2F3982352452&timestamp=1630048735&signature=72a227fed2dc24a90bcf68b45837af6c")
    time.sleep(10)

    button = browser.find_element_by_xpath('//div[@class="vcode-spin-button"]')
    ActionChains(browser).drag_and_drop_by_offset(button,xoffset=100, yoffset=0).perform()
    # ActionChains(browser).click_and_hold(on_element=button).perform()
    time.sleep(100)
#图片的抓取
def get_img():
    path = r"C:\Users\Administrator\AppData\Local\Google\Chrome\Application\chromedriver.exe"
    browser = webdriver.Chrome(executable_path=path)

    browser.get(
        "https://wappass.baidu.com/static/captcha/tuxing.html?ak=2ef521ec36290baed33d66de9b16f625&backurl=http%3A%2F%2Ftieba.baidu.com%2Fp%2F3982352452&timestamp=1630048735&signature=72a227fed2dc24a90bcf68b45837af6c")
    time.sleep(10)

    input = browser.find_element_by_xpath('//div[@class="vcode-spin-faceboder"]')
    time.sleep(5)
    browser.save_screenshot(r'E:\login.png')
    left = input.location['x']
    top = input.location['y']
    right = left + input.size['width']
    bottom = top + input.size['height']

    im = Image.open(r'E:\login.png')
    mg = im.crop((left, top, right, bottom))
    # 保存截图，命名未ann
    mg.save(r'E:\baidu_safe\realtime_img\{}.png'.format(1))

#改各个文件的文件名为各个角度的图片和正确图片的角度差。
def rename_angle_diff(right_img_index,img_path):
    file_list = os.listdir(img_path)
    for file in file_list:
        file_index = file.replace(".png",'')
        file_index = int(file_index)
        if file_index < right_img_index:
            new_index = file_index + 360 - right_img_index
        else:
            new_index = file_index - right_img_index
        curr_name = img_path + r'\\' + file
        new_name = img_path + r'\\' + str(new_index) + "__" + ".png"
        os.rename(curr_name, new_name)
    #去掉__
    file_list = os.listdir(img_path)
    for file in file_list:
        curr_name = img_path + r'\\' + file
        new_name = curr_name.replace("__","")
        os.rename(curr_name, new_name)
#删除文件
def delete_files(remove_list):
    for file in remove_list:
        os.remove(file)
#批量修改文件名
def update_filename(img_path):
    file_list = os.listdir(img_path)
    n = 0
    for file in file_list:
        curr_name = img_path + r'\\' + file
        # new_name = img_path + r'\\' + str(n) + r"__" + ".png"
        new_name = curr_name.replace("__","")
        print(curr_name,new_name)
        os.rename(curr_name,new_name)
        n = n + 1
#图片旋转，生成各个角度的图片
def rotation_img(img_path):
    file_list = os.listdir(img_path)
    for file in file_list:
        file_index = file.replace(".png",'')
        curr_file = r'E:\qqq\\' + file
        dir_path = r'E:\baidu_safe\all_angles\{}'.format(file_index)
        if os.path.exists(dir_path):
            pass
        else:
            os.mkdir(dir_path)
        for i in range(1,361):
            img = cv2.imread(curr_file)
            # cv2.namedWindow("Image")
            rows, cols, channel = img.shape
            M = cv2.getRotationMatrix2D((cols/2, rows/2), i, 1)
            dst = cv2.warpAffine(img, M, (cols, rows),borderValue=(255,255,255))
            # cv2.imshow('img', dst)
            # cv2.waitKey (0)

            cv2.imwrite(r'E:\baidu_safe\all_angles\{}\{}.png'.format(file_index,i),dst)
# path =r"C:\Users\Administrator\AppData\Local\Google\Chrome\Application\chromedriver.exe"
# browser = webdriver.Chrome(executable_path=path)

# img1 = Image.open(r"E:\353-10.png")
# img2 = Image.open(r"E:\341-230.png")
# diff = ImageChops.difference(img1, img2)
# if diff.getbbox() is None:
#     print("same")

# img = Image.open(r"E:\353.png")
# rotated_small = img.rotate(10, resample=Image.BICUBIC, expand=True)
# rotated_small.save(r"E:\353-10.png")
# 自定义计算两个图片相似度函数
def img_similarity(img1_path,img2_path):
    """
    :param img1_path: 图片1路径
    :param img2_path: 图片2路径
    :return: 图片相似度
    """
    try:
        # 读取图片
        img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)
        img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)

        # 初始化ORB检测器
        orb = cv2.ORB_create()
        kp1, des1 = orb.detectAndCompute(img1, None)
        kp2, des2 = orb.detectAndCompute(img2, None)

        # 提取并计算特征点
        bf = cv2.BFMatcher(cv2.NORM_HAMMING)

        # knn筛选结果
        matches = bf.knnMatch(des1, trainDescriptors=des2, k=2)

        # 查看最大匹配点数目
        good = [m for (m, n) in matches if m.distance < 0.75 * n.distance]
        # print(len(good))
        # print(len(matches))
        similary = len(good) / len(matches)
        # print("两张图片相似度为:%s" % similary)
        return similary

    except:
        print('无法计算两张图片相似度')
        return '0'
#SSIM结果相似度的计算
def calc_ssim(img1_path,img2_path):
    # 2. Construct the argument parse and parse the arguments
    # ap = argparse.ArgumentParser()
    # ap.add_argument("-f", "--first", required=True, help="Directory of the image that will be compared")
    # ap.add_argument("-s", "--second", required=True, help="Directory of the image that will be used to compare")
    # args = vars(ap.parse_args())

    # 3. Load the two input images
    imageA = cv2.imread(img1_path)
    imageB = cv2.imread(img2_path)

    # 4. Convert the images to grayscale
    grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)
    grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)

    # 5. Compute the Structural Similarity Index (SSIM) between the two
    #    images, ensuring that the difference image is returned
    (score, diff) = structural_similarity(grayA, grayB, full=True)
    diff = (diff * 255).astype("uint8")

    # 6. You can print only the score if you want
    # print("SSIM: {}".format(score))
    return score
#找出最相似的一张图片
def most_similar_image(img_path,identify_img):
    file_list = os.listdir(img_path)
    max = 0
    for file in file_list:
        curr_file = img_path + r'\\' + file
        value = img_similarity(curr_file,identify_img)
        if max < value:
            max = value
            similar_img = file

    return similar_img
if __name__ == '__main__':
    # update_filename(r'E:\qqq')
    # img1_path = r'E:\qqq\{}.png'.format(40)
    # img2_path = r'E:\qqq\{}.png'.format(25)
    # similary = img_similarity(img1_path, img2_path)
    # print("similary:{}\n".format(similary))

    # remove_list = []
    # for i in range(123):
    #     for j in range(i+1,124):
    #         img1_path = r'E:\qqq\{}.png'.format(i)
    #         img2_path = r'E:\qqq\{}.png'.format(j)
    #         similary = img_similarity(img1_path, img2_path)
    #         # ssim = calc_ssim(img1_path, img2_path)
    #         if similary > 0.3:
    #             print(similary)
    #             print("i:{},j:{}".format(i,j))
    #             remove_file = r'E:\qqq\{}.png'.format(j)
    #             if remove_file not in remove_list:
    #                 remove_list.append(remove_file)
    # print(remove_list)

    # #最相似的图片
    # r = most_similar_image(r"E:\baidu_safe\20",r"E:\reapit_img\326.png")
    # print(r)

    #图片旋转保存
    rotation_img(img_path)
    #计算个图片到正确图片的旋转角度

    # rename_angle_diff(80,r'E:\baidu_safe\20')
    # get_img()
    # r = most_similar_image(r"E:\baidu_safe\20", r"E:\reapit_img\326.png")

    # move_button()
```

[(145,0),(154,1),(73,2),(195,3),(143,4),(225,5),(250,6),(96,7),(155,8),(151,9),(145,10),(97,11),(133,12),(218,13),(225,14),(214,15),(113,16),(,17),(,18),(,19),(,20),(,21),(,22),(,23),(,24),(,25),(,26),(,27),(,28),(,29),(,30),(,31),(,32),(,33),(,34),(,35),(,36),(,37),(,38),(,39),(,40),(,41),(,42),(,43),(,44),(,45),(,46),(,47),(,48),(,49),(,50),(,51),(,52),(,53),(,54),(,55),(,56),(,57),(,58),(,59),(,60),(,61),(,62),(,63),(,64),(,65),(,66),(,67),(,68),(,69),(,70),(,71),(,72),(,73),(,74),(,75),(,76),(,77),(,78),(,79),(,80),(,81),(,82),(,83),(,84),(,85),(,86),(,87),(,88),(,89),(,90),(,91),(,92),(,93),(,94),(,95),(,96),(,97),(,98),(,99),(,100),(,101),(,102),(,103),(,104),(,105),(,106),(,107),(,108),(,109),(,110),(,111),(,112),(,113),(,114),(,115),(,116),(,117),(,118),(,119),(,120),(,121),(,122),(,123)]



![image-20210916154825192](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210916154825192.png![image-20210916160554861](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210916160554861.png)

```
result=WebDriverWait(driver,10).until(expected_conditions.element_located_selection_state_to_be((By.ID,'kw'),True))
```

twisted.internet.error.ReactorAlreadyRunning

```
from scrapy import signals, log
from twisted.internet import reactor
from scrapy.crawler import Crawler

class CrawlRunner:

    def __init__(self):
        self.running_crawlers = []

    def spider_closing(self, spider):
        log.msg("Spider closed: %s" % spider, level=log.INFO)
        self.running_crawlers.remove(spider)
        if not self.running_crawlers:
            reactor.stop()

    def run(self):

        sys.path.append(os.path.join(os.path.curdir, "crawl/somesite"))
        os.environ['SCRAPY_SETTINGS_MODULE'] = 'scrapy_somesite.settings'
        settings = get_project_settings()
        log.start(loglevel=log.DEBUG)

        to_crawl = [Spider1, Spider2]

        for spider in to_crawl:

            crawler = Crawler(settings)
            crawler_obj = spider()
            self.running_crawlers.append(crawler_obj)

            crawler.signals.connect(self.spider_closing, signal=signals.spider_closed)
            crawler.configure()
            crawler.crawl(crawler_obj)
            crawler.start()

        reactor.run()
```

太爱python了！
